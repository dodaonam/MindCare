from typing import Optional
import json
from fastapi import APIRouter
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from api.agent import chat_stream, new_session, end_session
from rag.agent_tools import get_last_sources
from rag.safety import safety_check
from rag.global_settings import init_llm_settings

router = APIRouter()

class ChatRequest(BaseModel):
    message: str
    session_id: Optional[str] = None

class SessionResponse(BaseModel):
    session_id: str
    success: bool

@router.post("/session/new", response_model=SessionResponse)
async def create_session():
    """Create a new chat session."""
    session_id = await new_session()
    return SessionResponse(session_id=session_id, success=True)

@router.delete("/session/{session_id}", response_model=SessionResponse)
async def delete_session(session_id: str):
    """End and clear a chat session."""
    success = await end_session(session_id)
    return SessionResponse(session_id=session_id, success=success)


@router.post("/chat")
async def chat_stream_endpoint(req: ChatRequest):
    """
    Streaming chat endpoint using Server-Sent Events (SSE)
    """
    user_msg = req.message
    session_id = req.session_id
    
    init_llm_settings()

    # Safety check
    safety = safety_check(user_msg)
    level = safety["level"]
    print("SAFETY CHECK:", safety)

    async def generate():
        nonlocal session_id
        
        # Send safety status first
        yield f"data: {json.dumps({'type': 'safety', 'data': safety})}\n\n"
        
        # Crisis case - don't stream, send full message
        if level == "crisis":
            crisis_msg = (
                "‚ö†Ô∏è M√¨nh r·∫•t ti·∫øc khi nghe ƒëi·ªÅu ƒë√≥. An to√†n c·ªßa b·∫°n l√∫c n√†y l√† quan tr·ªçng nh·∫•t.\n\n"
                "üëâ B·∫°n c√≥ th·ªÉ g·ªçi ngay **1900 1267 (ph√≠m 1)** ‚Äî ƒë∆∞·ªùng d√¢y h·ªó tr·ª£ kh·ªßng ho·∫£ng t√¢m l√Ω v√† tr·∫ßm c·∫£m, tr·ª±c 24/7.\n\n"
                "üëâ N·∫øu b·∫°n mu·ªën m·ªôt l·ª±a ch·ªçn kh√°c, b·∫°n c√≥ th·ªÉ g·ªçi **096 306 1414** ‚Äì ƒë∆∞·ªùng d√¢y 'Ng√†y Mai'.\n\n"
                "N·∫øu b·∫°n c·∫£m th·∫•y m√¨nh ƒëang g·∫∑p nguy hi·ªÉm ngay l√∫c n√†y, h√£y g·ªçi **115** ho·∫∑c ƒë·∫øn c∆° s·ªü y t·∫ø g·∫ßn nh·∫•t.\n\n"
                "B·∫°n kh√¥ng ƒë∆°n ƒë·ªôc ‚Äî h√£y t√¨m s·ª± h·ªó tr·ª£ ngay l√∫c n√†y."
            )
            yield f"data: {json.dumps({'type': 'crisis', 'data': crisis_msg})}\n\n"
            yield f"data: {json.dumps({'type': 'done', 'session_id': session_id})}\n\n"
            return
        
        # Warning case - send warning first
        if level == "warning":
            warning_msg = (
                "‚ö†Ô∏è M√¨nh c·∫£m nh·∫≠n ƒë∆∞·ª£c l√† b·∫°n ƒëang tr·∫£i qua m·ªôt giai ƒëo·∫°n kh√≥ khƒÉn. "
                "C·∫£m x√∫c nh∆∞ v·∫≠y ho√†n to√†n c√≥ th·∫≠t v√† ƒë√°ng ƒë·ªÉ l·∫Øng nghe. M√¨nh s·∫Ω lu√¥n ·ªü ƒë√¢y ƒë·ªÉ h·ªó tr·ª£ b·∫°n trong kh·∫£ nƒÉng c·ªßa m√¨nh.\n\n"
                "N·∫øu nh·ªØng c·∫£m x√∫c n√†y k√©o d√†i ho·∫∑c tr·ªü n√™n n·∫∑ng n·ªÅ h∆°n, "
                "b·∫°n c√≥ th·ªÉ c√¢n nh·∫Øc chia s·∫ª v·ªõi m·ªôt chuy√™n gia t√¢m l√Ω ho·∫∑c ng∆∞·ªùi th√¢n m√† b·∫°n tin t∆∞·ªüng. "
                "B·∫°n kh√¥ng c·∫ßn ph·∫£i t·ª± m√¨nh v∆∞·ª£t qua t·∫•t c·∫£ ƒë√¢u."
            )
            yield f"data: {json.dumps({'type': 'warning', 'data': warning_msg})}\n\n"
        
        # Stream the response
        try:
            async for token, sid in chat_stream(user_msg, session_id):
                session_id = sid  # Update session_id
                if token:
                    yield f"data: {json.dumps({'type': 'token', 'data': token})}\n\n"
            
            # Send sources at the end
            sources = get_last_sources()
            yield f"data: {json.dumps({'type': 'sources', 'data': sources})}\n\n"
            
        except Exception as e:
            yield f"data: {json.dumps({'type': 'error', 'data': str(e)})}\n\n"
        
        # Signal completion
        yield f"data: {json.dumps({'type': 'done', 'session_id': session_id})}\n\n"
    
    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )